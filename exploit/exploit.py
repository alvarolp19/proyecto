import os
import time
import json
from typing import List, Dict
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

def setup_driver() -> webdriver.Chrome:
    options = Options()
    options.headless = True
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--remote-debugging-port=9222")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    return webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)

def scrape_table(driver: webdriver.Chrome, url: str) -> List[Dict[str, str]]:
    driver.get(url)
    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'exploits-table')))
    time.sleep(2)  # Ensure table is fully loaded

    table = driver.find_element(By.ID, 'exploits-table')
    rows = table.find_elements(By.TAG_NAME, 'tr')

    incidentes = []
    for row in rows[1:]:
        cols = row.find_elements(By.TAG_NAME, 'td')
        incidente = {
            'Date': cols[0].text.strip(),
            'D': cols[1].text.strip(),
            'A': cols[2].text.strip(),
            'V': cols[3].text.strip(),
            'Title': cols[4].text.strip(),
            'Type': cols[5].text.strip(),
            'Platform': cols[6].text.strip(),
            'Author': cols[7].text.strip()
        }
        incidentes.append(incidente)

    return incidentes

def load_records(filename: str) -> List[Dict[str, str]]:
    try:
        with open(filename, 'r') as file:
            return json.load(file)
    except FileNotFoundError:
        return []

def save_records(data: List[Dict[str, str]], filename: str) -> None:
    with open(filename, 'w') as file:
        json.dump(data, file, indent=4)

def ensure_directory_exists(directory: str) -> None:
    if not os.path.exists(directory):
        os.makedirs(directory)

def main():
    url = 'https://www.exploit-db.com/'
    registros_filename = 'registros.json'
    directorio_registros_diarios = 'registros_diarios'
    
    ensure_directory_exists(directorio_registros_diarios)
    
    driver = setup_driver()
    try:
        nuevos_incidentes = scrape_table(driver, url)
    finally:
        driver.quit()
    
    registro_completo = load_records(registros_filename)
    
    nuevas_entradas = [incidente for incidente in nuevos_incidentes if incidente not in registro_completo]
    registro_completo.extend(nuevas_entradas)
    
    save_records(registro_completo, registros_filename)
    
    fecha_hora_actual = time.strftime("%Y-%m-%d_%H-%M-%S")
    nombre_archivo_nuevos = f"{directorio_registros_diarios}/registro_{fecha_hora_actual}.json"
    save_records(nuevas_entradas, nombre_archivo_nuevos)
    
    print(f"Datos almacenados en {registros_filename} y {nombre_archivo_nuevos}")

if __name__ == "__main__":
    main()

